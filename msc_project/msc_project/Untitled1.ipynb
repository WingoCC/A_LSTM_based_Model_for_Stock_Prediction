{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba31ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.4.3-py3-none-any.whl (985 kB)\n",
      "\u001b[K     |████████████████████████████████| 985 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "\u001b[K     |████████████████████████████████| 358 kB 68.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: sortedcontainers in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/ubuntu/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.4.3 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82abeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741a376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benzinga_data(stock, days_to_look_back):\n",
    "\tffox_options = webdriver.FirefoxOptions()\n",
    "\tminimum_date = pd.Timestamp(datetime.utcnow(), tz = 'UTC') - pd.Timedelta('{} days'.format(days_to_look_back))\n",
    "\tffox_options.set_headless()\n",
    "\ttol_amount = 5\n",
    "\ttols_curr = 0\n",
    "\tbp = False\n",
    "\tff = webdriver.Firefox(options = ffox_options)\n",
    "\ttry:\n",
    "\t\tff.get('https://benzinga.com/stock/{}'.format(stock.lower()))\n",
    "\t\ttime.sleep(5)\n",
    "\t\tanalyst_ratings = []\n",
    "\t\tcurrent_index = 1\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\telem = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/a/span[1]')\n",
    "\t\t\t\tff.execute_script(\"arguments[0].scrollIntoView();\", elem)\n",
    "\t\t\t\ttime.sleep(0.3)\n",
    "\t\t\t\telem.click()\n",
    "\t\t\t\ttime.sleep(2)\n",
    "\n",
    "\t\t\t\twhile True:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\theader = '/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/a'.format(current_index)\n",
    "\t\t\t\t\t\theadline = ff.find_element_by_xpath(header).text\n",
    "\t\t\t\t\t\turl = ff.find_element_by_xpath(header).get_attribute('href')\n",
    "\t\t\t\t\t\tpublisher = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/span[1]'.format(current_index)).text\n",
    "\t\t\t\t\t\tdate = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/span[2]'.format(current_index)).text\n",
    "\t\t\t\t\t\t# print(date)\n",
    "\t\t\t\t\t\t# print([headline, date])\n",
    "\t\t\t\t\t\tif ('-0400' not in date) & ('-0500' not in date):\n",
    "\t\t\t\t\t\t\t# # print(date)\n",
    "\t\t\t\t\t\t\tif 'ago' in date:\n",
    "\t\t\t\t\t\t\t\tif date == 'a day ago':\n",
    "\t\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\t\telse:\n",
    "\n",
    "\t\t\t\t\t\t\t\t\t# # print(date)\n",
    "\t\t\t\t\t\t\t\t\ttimeperiod = date[::-1]\n",
    "\t\t\t\t\t\t\t\t\ttimeperiod = timeperiod[timeperiod.find(' ') + 1:][::-1]\n",
    "\t\t\t\t\t\t\t\t\ttimeperiod = pd.Timedelta(timeperiod)\n",
    "\t\t\t\t\t\t\t\t\t# print('FINDME!!!!')\n",
    "\t\t\t\t\t\t\t\t\t# print(days_to_look_back)\n",
    "\t\t\t\t\t\t\t\t\t# print(timeperiod)\n",
    "\t\t\t\t\t\t\t\t\t# print(pd.Timedelta('{} days'.format(days_to_look_back)) > timeperiod)\n",
    "\t\t\t\t\t\t\t\t\tif timeperiod > pd.Timedelta('{} days'.format(days_to_look_back)):\n",
    "\t\t\t\t\t\t\t\t\t\tbp = True\n",
    "\t\t\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# # print(date)\n",
    "\t\t\t\t\t\t\t\tdate = pd.Timestamp(date, tz = 'America/Detroit')\n",
    "\t\t\t\t\t\t\t\tif date < minimum_date - pd.Timedelta('1 day'):\n",
    "\t\t\t\t\t\t\t\t\tbp = True\n",
    "\t\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tanalyst_ratings.append([headline, url, publisher, date])\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tcurrent_index += 1\n",
    "\t\t\t\t\t\t# print(current_index)\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\t# print(e)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tif bp:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\t# ff.dismiss()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('//*[@id=\"onesignal-popover-cancel-button\"]').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED')\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('/html/body/div[22]/div/div/button').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED (1)')\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('//*[@id=\"shreveport-ButtonElement--zs4zLUkKVVfSEq8qDkow\"]').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED (2)')\n",
    "\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\t\t\ttols_curr += 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif tol_amount < tols_curr:\n",
    "\t\t\t\t\tbreak\n",
    "\t\tff.close()\n",
    "\t\tdef get_basic_data_for_url(url):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tpage = requests.get(url)\n",
    "\t\t\t\ttext = page.text\n",
    "\t\t\t\tsoup = BeautifulSoup(text, 'html.parser')\n",
    "\t\t\t\tdate = soup.findAll('span', {'class': 'date'})[0].text\n",
    "\t\t\t\ttree = html.fromstring(page.content)\n",
    "\t\t\t\ttitle = tree.xpath('//*[@id=\"title\"]')[0].text\n",
    "\t\t\t\treturn title, date\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\treturn np.nan, np.nan\n",
    "\t\tanalyst_ratings = pd.DataFrame(analyst_ratings, columns = ['headline', 'url', 'publisher', 'date'])\n",
    "\t\tdatas = []\n",
    "\t\tfor i in analyst_ratings.index:\n",
    "\t\t\turl = analyst_ratings.loc[i, 'url']\n",
    "\t\t\tdatas.append(get_basic_data_for_url(url))\n",
    "\t\tdatas = pd.DataFrame(datas, columns = ['headline', 'date'])\n",
    "\t\tanalyst_ratings[datas.columns] = datas\n",
    "\t\treturn analyst_ratings\t\n",
    "\texcept Exception as e:\n",
    "\t\t# print(e)\n",
    "\t\tff.close()\n",
    "def get_benzinga_data(stock):\n",
    "\tffox_options = webdriver.FirefoxOptions()\n",
    "\tffox_options.set_headless()\n",
    "\ttol_amount = 5\n",
    "\ttols_curr = 0\n",
    "\tff = webdriver.Firefox(options = ffox_options)\n",
    "\ttry:\n",
    "\t\tff.get('https://benzinga.com/stock/{}'.format(stock.lower()))\n",
    "\t\ttime.sleep(5)\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\telem = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/a/span[1]')\n",
    "\t\t\t\tff.execute_script(\"arguments[0].scrollIntoView();\", elem)\n",
    "\t\t\t\ttime.sleep(0.3)\n",
    "\t\t\t\telem.click()\n",
    "\t\t\t\ttime.sleep(2)\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# ff.dismiss()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('//*[@id=\"onesignal-popover-cancel-button\"]').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED')\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('/html/body/div[21]/div/div/div/div/div/div/div/div[1]/div/div/div/div/div/div[4]/div/div').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED (2)')\n",
    "\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\t\t\ttols_curr += 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif tol_amount < tols_curr:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\t\tanalyst_ratings = []\n",
    "\t\tcurrent_index = 1\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\theader = '/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/a'.format(current_index)\n",
    "\t\t\t\theadline = ff.find_element_by_xpath(header).text\n",
    "\t\t\t\turl = ff.find_element_by_xpath(header).get_attribute('href')\n",
    "\t\t\t\tpublisher = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/span[1]'.format(current_index)).text\n",
    "\t\t\t\tdate = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[7]/div/div/div[1]/ul/li[{}]/span[2]'.format(current_index)).text\n",
    "\t\t\t\tanalyst_ratings.append([headline, url, publisher, date])\n",
    "\t\t\t\t# print(analyst_ratings[-1])\n",
    "\t\t\t\tcurrent_index += 1\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\tbreak\n",
    "\t\tanalyst_ratings = pd.DataFrame(analyst_ratings, columns = ['headline', 'url', 'publisher', 'date'])\n",
    "\t\tanalyst_ratings.to_csv('benzinga_scrape/analyst_ratings/{}.csv'.format(stock))\n",
    "\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\telem = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[9]/div/div/div/a/span[1]')\n",
    "\t\t\t\tff.execute_script(\"arguments[0].scrollIntoView();\", elem)\n",
    "\t\t\t\ttime.sleep(0.3)\n",
    "\t\t\t\telem.click()\n",
    "\t\t\t\ttime.sleep(2)\n",
    "\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# ff.dismiss()\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('//*[@id=\"onesignal-popover-cancel-button\"]').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED')\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tff.find_element_by_xpath('/html/body/div[21]/div/div/div/div/div/div/div/div[1]/div/div/div/div/div/div[4]/div/div').click()\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\t\t\t# print('FAILED (2)')\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\t\t\ttols_curr += 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tif tol_amount < tols_curr:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\t\tpartner_headlines = []\n",
    "\t\tcurrent_index = 1\n",
    "\t\twhile True:\n",
    "\t\t\ttry:\n",
    "\t\t\t\theader = '/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[9]/div/div/div/ul/li[{}]/a'.format(current_index)\n",
    "\t\t\t\theadline = ff.find_element_by_xpath(header).text\n",
    "\t\t\t\turl = ff.find_element_by_xpath(header).get_attribute('href')\n",
    "\t\t\t\tpublisher = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[9]/div/div/div/ul/li[{}]/span[1]'.format(current_index)).text\n",
    "\t\t\t\tdate = ff.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/div[1]/div/div[9]/div/div/div/ul/li[{}]/span[2]'.format(current_index)).text\n",
    "\t\t\t\tpartner_headlines.append([headline, url, publisher, date])\n",
    "\t\t\t\t# print(partner_headlines[-1])\n",
    "\t\t\t\tcurrent_index += 1\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\t# print(e)\n",
    "\t\t\t\tbreak\n",
    "\t\tpartner_headlines = pd.DataFrame(partner_headlines, columns = ['headline', 'url', 'publisher', 'date'])\n",
    "\t\tpartner_headlines.to_csv('benzinga_scrape/partner_headlines/{}.csv'.format(stock))\n",
    "\t\tff.close()\t\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\tff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742786f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
